# AWs Services

What is AWS CodeCommit?

AWS CodeCommit is a fully managed source control service that hosts Git repositories, allowing teams to securely store and manage their code assets.

What is AWS CodeBuild?

AWS CodeBuild is a fully managed build service that compiles source code, runs tests, and produces deployable artifacts, providing continuous integration and automated build capabilities.

What is AWS CodeDeploy?

AWS CodeDeploy is a fully managed deployment service that automates application deployments to various compute services, including Amazon EC2 instances, AWS Lambda, and on-premises servers.

How does AWS CodeDeploy work?

AWS CodeDeploy works by deploying applications from source code or artifacts stored in repositories, and then automating the deployment process across multiple instances, ensuring reliability and minimizing downtime.

What is AWS Code Pipeline?

AWS Code Pipeline is a fully managed continuous delivery service that orchestrates the build, test, and deployment of applications, enabling fast and reliable software releases.

What is AWS Elastic Beanstalk?

AWS Elastic Beanstalk is a fully managed platform-as-a-service (PaaS) that allows you to deploy and run applications without managing the underlying infrastructure. It supports various programming languages and application stacks.

What is AWS CloudFormation?

AWS CloudFormation is a service that allows you to create and manage AWS resources using declarative JSON or YAML templates, enabling infrastructure-as-code and automated provisioning.

What is AWS CloudWatch?

AWS CloudWatch is a monitoring and observability service that provides metrics, logs, and events for AWS resources and applications, allowing you to gain insights and take automated actions.

How can you automate infrastructure deployments in AWS?

You can automate infrastructure deployments in AWS by using services like AWS CloudFormation, AWS CDK (Cloud Development Kit), or Infrastructure-as-Code (IaC) tools like Terraform, enabling you to define and provision resources in a repeatable and automated manner.

What is AWS Lambda?

AWS Lambda is a serverless compute service that allows you to run code without provisioning or managing servers. It scales automatically and charges you based on the actual compute time consumed.

How can you automate serverless application deployments in AWS?

You can automate serverless application deployments in AWS by using services like AWS SAM (Serverless Application Model), AWS CloudFormation, or CI/CD tools integrated with AWS Lambda, allowing you to define and deploy your serverless application resources.

What is AWS X-Ray?

AWS X-Ray is a service that helps you analyze and debug distributed applications, providing insights into application performance and the ability to trace requests across various components.

What is AWS Elastic Beanstalk?

AWS Elastic Beanstalk is a fully managed platform-as-a-service (PaaS) that allows you to deploy and run applications without managing the underlying infrastructure. It supports various programming languages and application stacks.

What is AWS OpsWorks?

AWS OpsWorks is a configuration management service that uses Chef or Puppet to automate the provisioning and management of applications and resources in AWS.

What is AWS Systems Manager?

AWS Systems Manager provides a unified interface for managing and monitoring resources in AWS, allowing you to automate operational tasks, configure resources, and collect insights.

What is AWS CloudTrail?

AWS CloudTrail is a service that enables governance, compliance, and auditing of AWS account activities by recording API calls and storing the resulting logs for analysis.

What is AWS Elastic Load Balancer (ELB)?

AWS Elastic Load Balancer automatically distributes incoming application traffic across multiple targets, such as EC2 instances, containers, and IP addresses, enhancing the availability and scalability of applications.

What is AWS Auto Scaling?

AWS Auto Scaling automatically adjusts the capacity of AWS resources, such as EC2 instances or DynamoDB throughput, based on predefined scaling policies, ensuring optimal performance and cost efficiency.

What is the difference between horizontal and vertical scaling?

Horizontal scaling involves adding more instances or resources to distribute the load across multiple machines, while vertical scaling involves increasing the resources of an existing instance or machine to handle increased load.

What is the purpose of AWS CloudWatch Events?

AWS CloudWatch Events allows you to respond to operational changes in your AWS resources by triggering automated actions based on events, such as changes to EC2 instances or S3 buckets.

What is AWS Systems Manager Parameter Store?

AWS Systems Manager Parameter Store is a managed service that allows you to store and retrieve configuration data and secrets, such as database credentials, as secure key-value pairs.

What is AWS Secrets Manager?

AWS Secrets Manager is a secrets management service that helps you protect access to applications, services, and resources by securely storing and managing secrets like API keys and database credentials.

How can you ensure security in AWS environments?

You can ensure security in AWS environments by following security best practices, implementing proper identity and access management (IAM), encrypting data at rest and in transit, implementing network security controls, and regularly auditing and monitoring your resources.

What is AWS Identity and Access Management (IAM)?

AWS IAM is a web service that enables you to securely control access to AWS resources. It allows you to create and manage users, groups, roles, and permissions to grant appropriate access to resources.

What is AWS Key Management Service (KMS)?

AWS Key Management Service (KMS) is a managed service that allows you to create and control the encryption keys used to encrypt your data stored in AWS services or applications.

What is the AWS Well-Architected Framework?

The AWS Well-Architected Framework provides guidance on designing and operating secure, high-performing, resilient, and efficient infrastructure in the cloud.

How can you implement high availability in AWS?

You can implement high availability in AWS by using services like Elastic Load Balancer, Auto Scaling, and deploying resources across multiple Availability Zones (AZs) to ensure redundancy and fault tolerance.

What is AWS CloudFormation Change Sets?

AWS CloudFormation Change Sets allow you to preview and deploy the changes to your AWS CloudFormation stacks before making any actual modifications, reducing the risk of unintended changes.

What is the AWS Server Migration Service?

The AWS Server Migration Service is a service that helps migrate on-premises workloads to AWS, enabling seamless and automated migration of virtual machines, physical servers, and databases.

What is AWS Artifact?

AWS Artifact is a portal that provides access to AWS compliance reports, such as Service Organization Control (SOC) reports, Payment Card Industry (PCI) reports, and other security and compliance documentation.

What is the AWS Well-Architected Tool?

The AWS Well-Architected Tool is a service that helps review and improve the architectures of workloads running on AWS, providing recommendations based on the best practices outlined in the AWS Well-Architected Framework.

How can you implement fault tolerance in AWS?

You can implement fault tolerance in AWS by designing applications to automatically recover from failures using features like Auto Scaling, Elastic Load Balancer, and multiple Availability Zones.

What is AWS CloudFront?

AWS CloudFront is a global content delivery network (CDN) service that accelerates the delivery of your web content, including dynamic, static, and streaming content.

What is AWS Route 53?

AWS Route 53 is a scalable and highly available domain name system (DNS) web service that routes end users to applications by translating domain names into IP addresses.

What is AWS S3?

AWS S3 (Simple Storage Service) is a highly scalable object storage service that allows you to store and retrieve data from anywhere on the web. It provides durability, availability, and security for your data.

What is AWS RDS?

AWS RDS (Relational Database Service) is a managed database service that simplifies the setup, operation, and scaling of relational databases, such as MySQL, PostgreSQL, Oracle, and SQL Server.

What is AWS DynamoDB?

AWS DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. It is designed to handle large amounts of data and high-traffic applications.

What is AWS CloudWatch Logs?

AWS CloudWatch Logs is a service that allows you to monitor, store, and access log files from AWS resources and applications. It helps you troubleshoot issues, track system behavior, and gain insights from log data.

What is AWS CloudTrail?

AWS CloudTrail is a service that enables governance, compliance, and auditing of AWS account activities by recording API calls and storing the resulting logs for analysis.

What is AWS Kinesis?

AWS Kinesis is a platform for streaming data at any scale, enabling you to collect, process, and analyze real-time streaming data from various sources.

What is AWS SQS?

AWS SQS (Simple Queue Service) is a fully managed message queuing service that enables you to decouple and scale distributed systems by allowing components to communicate asynchronously.

What is AWS SNS?

AWS SNS (Simple Notification Service) is a fully managed messaging service that enables you to send notifications and messages to individuals or groups using various communication protocols.

What is AWS Elasticache?

AWS Elasticache is a fully managed in-memory caching service that helps improve the performance and scalability of web applications by caching frequently accessed data.

What is AWS Step Functions?

AWS Step Functions is a serverless workflow service that enables you to coordinate multiple AWS services and build applications using visual workflows.

What is AWS Batch?

AWS Batch is a fully managed service that enables you to run batch computing workloads at any scale, efficiently managing and optimizing the distribution of your workloads across EC2 instances.

What is AWS Cloud9?

AWS Cloud9 is a cloud-based integrated development environment (IDE) that allows you to write, run, and debug code in a browser. It supports various programming languages and integrates with other AWS services.

What is the AWS Command Line Interface (CLI)?

The AWS Command Line Interface (CLI) is a unified tool that allows you to manage and control your AWS services from the command line. It provides a simple and efficient way to interact with AWS resources.

What is AWS Systems Manager Session Manager?

AWS Systems Manager Session Manager is a fully managed service that provides secure and auditable instance management without the need for SSH or RDP access. It allows you to establish secure shell (SSH) or remote desktop protocol (RDP) connections to your instances directly from the AWS Management Console.

What is AWS CloudFormation StackSets?

AWS CloudFormation StackSets allow you to create, update, or delete stacks across multiple AWS accounts and regions, simplifying the management of resources and configurations at scale.

What is the AWS Serverless Application Model (SAM)?

The AWS Serverless Application Model (SAM) is an open-source framework that extends AWS CloudFormation to simplify the deployment and management of serverless applications on AWS.

What is AWS CodeStar?

AWS CodeStar is a fully managed service that provides a unified user interface, integrations, and templates for developing, building, and deploying applications on AWS.

What is AWS CodeArtifact?

AWS CodeArtifact is a fully managed artifact repository service that allows you to securely store, publish, and share software packages, dependencies, and artifacts.

What is AWS CodeGuru?

AWS CodeGuru is a developer tool powered by machine learning that provides automated code reviews and performance recommendations, helping you improve the quality and efficiency of your applications.

What is AWS CodeDeploy?

AWS CodeDeploy is a fully managed deployment service that automates application deployments to various compute services, including Amazon EC2 instances, AWS Lambda, and on-premises servers.

What is AWS CodeCommit?

AWS CodeCommit is a fully managed source control service that hosts Git repositories, allowing teams to securely store and manage their code assets.

What is AWS CodeBuild?

AWS CodeBuild is a fully managed build service that compiles source code, runs tests, and produces deployable artifacts, providing continuous integration and automated build capabilities.

What is AWS CodePipeline?

AWS CodePipeline is a fully managed continuous delivery service that orchestrates the build, test, and deployment of applications, enabling fast and reliable software releases.

What is AWS CodeStar Connections?

AWS CodeStar Connections is a service that allows you to securely connect your third-party Git repositories, such as GitHub or Bitbucket, to AWS development tools like AWS CodePipeline and AWS CodeBuild.

What is AWS CodeStar Notifications?

AWS CodeStar Notifications is a service that provides a unified interface to configure and manage notifications for events occurring in your software development lifecycle (SDLC) tools, such as code commits, build completions, and deployment status changes.

What is AWS AppConfig?

AWS AppConfig is a managed application configuration service that helps you deploy and manage application configurations across distributed systems, allowing you to quickly roll out changes and ensure configuration consistency.

What is AWS Cloud9?

AWS Cloud9 is a cloud-based integrated development environment (IDE) that allows you to write, run, and debug code in a browser. It supports various programming languages and integrates with other AWS services.

What is AWS CloudFormation StackSets?

AWS CloudFormation StackSets allow you to create, update, or delete stacks across multiple AWS accounts and regions, simplifying the management of resources and configurations at scale.

What is AWS Systems Manager Session Manager?

AWS Systems Manager Session Manager is a fully managed service that provides secure and auditable instance management without the need for SSH or RDP access. It allows you to establish secure shell (SSH) or remote desktop protocol (RDP) connections to your instances directly from the AWS Management Console.

What is AWS Secrets Manager?

AWS Secrets Manager is a secrets management service that helps you protect access to applications, services, and resources by securely storing and managing secrets like API keys and database credentials.

What is AWS Step Functions?

AWS Step Functions is a serverless workflow service that enables you to coordinate multiple AWS services and build applications using visual workflows.

What is AWS Lambda?

AWS Lambda is a serverless compute service that allows you to run code without provisioning or managing servers. It scales automatically and charges you based on the actual compute time consumed.

What is AWS Elastic Beanstalk?

AWS Elastic Beanstalk is a fully managed platform-as-a-service (PaaS) that allows you to deploy and run applications without managing the underlying infrastructure. It supports various programming languages and application stacks.

What is AWS Elastic Load Balancer (ELB)?

AWS Elastic Load Balancer automatically distributes incoming application traffic across multiple targets, such as EC2 instances, containers, and IP addresses, enhancing the availability and scalability of applications.

What is AWS Auto Scaling?

AWS Auto Scaling automatically adjusts the capacity of AWS resources, such as EC2 instances or DynamoDB throughput, based on predefined scaling policies, ensuring optimal performance and cost efficiency.

What is AWS CloudWatch?

AWS CloudWatch is a monitoring and observability service that provides metrics, logs, and events for AWS resources and applications, allowing you to gain insights and take automated actions.

What is AWS X-Ray?

AWS X-Ray is a service that helps you analyze and debug distributed applications, providing insights into application performance and the ability to trace requests across various components.

What is AWS CloudTrail?

AWS CloudTrail is a service that enables governance, compliance, and auditing of AWS account activities by recording API calls and storing the resulting logs for analysis.

What is AWS CodeDeploy?

AWS CodeDeploy is a fully managed deployment service that automates application deployments to various compute services, including Amazon EC2 instances, AWS Lambda, and on-premises servers.

What is AWS CodeCommit?

AWS CodeCommit is a fully managed source control service that hosts Git repositories, allowing teams to securely store and manage their code assets.

What is AWS CodeBuild?

AWS CodeBuild is a fully managed build service that compiles source code, runs tests, and produces deployable artifacts, providing continuous integration and automated build capabilities.

What is AWS CodePipeline?

AWS CodePipeline is a fully managed continuous delivery service that orchestrates the build, test, and deployment of applications, enabling fast and reliable software releases.

What is AWS OpsWorks?

AWS OpsWorks is a configuration management service that uses Chef or Puppet to automate the provisioning and management of applications and resources in AWS.

What is AWS Systems Manager?

AWS Systems Manager provides a unified interface for managing and monitoring resources in AWS, allowing you to automate operational tasks, configure resources, and collect insights.

What is AWS CloudFormation?

AWS CloudFormation is a service that allows you to create and manage AWS resources using declarative JSON or YAML templates, enabling infrastructure-as-code and automated provisioning.

What is AWS CloudFront?

AWS CloudFront is a global content delivery network (CDN) service that accelerates the delivery of your web content, including dynamic, static, and streaming content.

What is AWS Route 53?

AWS Route 53 is a scalable and highly available domain name system (DNS) web service that routes end users to applications by translating domain names into IP addresses.

_____________________

## AWS arquitect

Being well-prepared is crucial for any tech interview, especially when aiming for a specialized position in cloud computing. For those eager to secure a role in cloud architecture, understanding the nuances of AWS-related questions can significantly bolster your chances.

In this article, we discuss AWS interview questions that may come up when interviewing for Solution Architect roles. For these cloud jobs the AWS Certified Solutions Architect — Associate certification is a highly valuable certification to earn.

The AWS Certified Solutions Architect — Associate is a fundamental certification geared towards those who design distributed systems and applications on the AWS platform. It’s an invaluable credential for individuals stepping into the world of AWS architecture or seeking to deepen their existing knowledge.

The role of an AWS Solutions Architect Associate is pivotal in the modern cloud ecosystem. With an ever-growing demand for cloud services, businesses are keen on hiring professionals who can design, manage, and implement sophisticated cloud solutions on AWS. This means, as a candidate, one should be well-prepared to address both fundamental and intricate aspects of AWS services and best practices.

The AWS Solutions Architect Associate certification is evidence of your advanced knowledge in this area, but to excel in an interview, you need more than just the certification. You need an understanding of real-world scenarios, challenges, and solutions.

Whether you are preparing for an upcoming interview or are on the hiring side and need to gauge a candidate’s depth of knowledge, this list of 20 comprehensive interview questions will set you up for success.

Let’s dive into these AWS architect interview questions and help you gear up for success in your interview.

1. How would you design a fault-tolerant architecture on AWS?

Answer: Designing a fault-tolerant architecture in AWS involves utilizing multiple Availability Zones for redundancy, implementing Elastic Load Balancing to distribute incoming traffic across instances, auto-scaling to match demand, and using AWS services like Amazon S3 and Amazon RDS for data durability. Regularly backing up data and having a disaster recovery plan in place, along with monitoring system health using Amazon CloudWatch, are also critical practices.

2. What are the benefits of using Amazon EC2 instances within an Auto Scaling group?

Answer: Auto Scaling ensures that Amazon EC2 instances adjust according to the defined conditions, maintaining application availability and balancing capacity. It helps in cost reduction by adjusting the number of instances in use based on demand, thereby avoiding the need to pay for idle computing resources. Auto Scaling in various instances across multiple Availability Zones can also increase the fault tolerance of your applications.

3. Explain the significance of a Virtual Private Cloud (VPC) in AWS.

Answer: A VPC enables you to launch AWS resources into a virtual network that you’ve defined. This virtual network closely resembles a traditional network that you’d operate in your own data center, with the benefits of using the scalable infrastructure of AWS. It provides control over your virtual networking environment, including selection of your own IP address range, the creation of subnets, and configuration of route tables and network gateways.

4. What strategies would you use to optimize the costs of AWS services for a project?

Answer: Cost optimization in AWS can involve several strategies: choosing the right pricing models (e.g., Reserved Instances, Spot Instances), correctly estimating traffic and choosing the appropriate instance types, using Auto Scaling to adjust resources, monitoring and analyzing with AWS Cost Explorer, utilizing cheaper storage options for infrequently accessed data, and employing AWS Budgets and AWS Trusted Advisor for cost monitoring and recommendations.

5. How can AWS Direct Connect be beneficial for an organization?

Answer: AWS Direct Connect allows an organization to establish a dedicated network connection between one’s network and AWS data centers. This provides a more stable and reliable connection and can reduce network costs, increase bandwidth throughput, and provide a more consistent network experience than internet-based connections. It’s particularly beneficial for high throughput workloads or transferring large amounts of data.


Click the image above to watch this video from our youtube channel

6. In a hybrid cloud architecture, how can you securely integrate on-premises datacenters with AWS?

Answer: Secure integration in a hybrid cloud model can be achieved through several means: AWS VPN allows you to establish a secure and private encrypted tunnel from your network or device to the AWS global network. AWS Direct Connect bypasses the public Internet and establishes a secure, dedicated connection from your premises to AWS. Additionally, using AWS Transit Gateway, you can connect your on-premises datacenters to AWS with a single gateway, simplifying your network and putting in place more stringent security measures.

7. What is Amazon S3’s consistency model?

Answer: Amazon S3 provides strong read-after-write consistency for PUTS of new objects and eventual consistency for overwrite PUTS and DELETES. This means that if a new object is written to S3, any subsequent retrieval requests will return the latest version of the object. However, for updates and deletes, it might take some time for the changes to propagate, and requests made in the interim might return old data.

8. How do you ensure high availability and disaster recovery in AWS?

Answer: High availability and disaster recovery involve multiple AWS services and features:

Utilize multiple Availability Zones and Regions to ensure that applications can handle the loss of entire data centers.
Implement Amazon RDS or Amazon Aurora Multi-AZ deployments to automate database setup, patching, and backups.
Use Amazon S3 for durable, scalable, and secure object storage with built-in lifecycle policies for automated backup and storage management.
Employ AWS CloudFormation for infrastructure as code and quick re-provisioning of resources in a disaster recovery scenario.
Implement AWS Shield and AWS WAF for resilience against DDoS attacks.
9. How does AWS assist in the deployment of hybrid applications?

Answer: AWS offers various services to facilitate hybrid deployments. AWS Outposts extends AWS’s infrastructure, services, APIs, and tools to virtually any datacenter or on-premises facility for a truly consistent hybrid experience. AWS Storage Gateway connects on-premises software applications with cloud-based storage. Amazon RDS on VMware lets you deploy managed databases in on-premises VMware environments, and AWS Direct Connect establishes a dedicated network connection from an on-premises network to AWS.

10. What are the key aspects to consider while planning a migration to AWS cloud?

Answer: Key considerations include:

Assessing the existing on-premises infrastructure and understanding the technical requirements.
Deciding on a suitable migration strategy (like re-hosting, re-platforming, re-factoring, re-purchasing, retiring, or retaining).
Calculating the total cost of ownership and potential cost savings.
Planning for security and compliance.
11: How do Amazon S3 transfer acceleration and Amazon CloudFront differ in terms of content delivery?

Answer: Amazon S3 Transfer Acceleration is specifically designed to speed up transferring files to and from Amazon S3 by utilizing Amazon CloudFront’s globally distributed edge locations. When users upload or download files, the data will travel through the optimized network path to reach the S3 bucket faster. On the other hand, Amazon CloudFront is a content delivery network (CDN) that caches content in edge locations around the world, bringing the content closer to the end-users and reducing latency. While both involve CloudFront’s edge locations, S3 Transfer Acceleration is for faster transfers to S3, and CloudFront is for general content distribution to end-users.

12. What are placement groups in EC2, and can you describe the different types?

Answer: Placement groups are a way of controlling how EC2 instances are physically located relative to one another. There are three types:

Cluster Placement Groups: Used for applications needing low network latency and high network throughput, ensuring instances are placed in a single availability zone.

Spread Placement Groups: Ensures that instances are placed on distinct underlying hardware, reducing correlated failures and suitable for a small number of critical instances.

Partition Placement Groups: Spread instances across different partitions, ensuring that instances in one partition do not share the underlying hardware with instances in other partitions.

13. Describe AWS Organizations and its primary use cases. How does it help in managing multiple AWS accounts?

Answer: AWS Organizations lets you consolidate multiple AWS accounts into an organization that you create and centrally manage. Primary use cases include centralized billing, setting up and managing accounts, applying and managing service control policies across accounts, and creating a hierarchical, multi-account structure. AWS Organizations simplifies billing for multiple accounts by enabling the setup of a single payment method for all the accounts in your organization through consolidated billing.

14. How would you design a multi-region architecture for high availability on AWS?

Answer: Designing a multi-region architecture involves replicating data and applications in more than one geographic region. This is achieved by setting up application stacks in multiple AWS regions, utilizing Amazon Route 53 for geo-based routing, replicating data using services like Amazon RDS cross-region replication or S3 Cross-Region Replication, and ensuring stateless applications to quickly scale and replicate.

15. What is the difference between an Application Load Balancer (ALB) and a Network Load Balancer (NLB)? When would you choose one over the other?

Answer: ALB is layer 7 (application layer) load balancer, suitable for routing user traffic based on content type, path, or host in the request. It’s ideal for HTTP/HTTPS traffic. NLB operates at layer 4 (transport layer) and is designed for TCP/UDP traffic where extreme performance is required. NLB is chosen for ultra-high levels of traffic or when low-level routing is necessary.

16. Explain the process of automating infrastructure deployment using AWS CloudFormation. What are CloudFormation templates?

Answer: AWS CloudFormation automates and simplifies the task of repeatedly and predictably creating groups of related resources that power your applications. The process involves writing a CloudFormation template in JSON or YAML format. This template defines the AWS resources you want to deploy. Once the template is created, you can use CloudFormation to create a stack based on the template, which will provision the defined resources.

17. Describe the benefits of using Amazon Aurora over traditional RDS databases. How does Aurora ensure fault tolerance and scalability?

Answer: Amazon Aurora is a MySQL and PostgreSQL-compatible relational database that combines the speed and availability of high-end commercial databases with the simplicity and cost-effectiveness of open-source databases. Benefits include up to 5 times the performance of MySQL and 3 times the performance of PostgreSQL. Aurora automatically divides your database volume into 10GB segments spread across many disks. Each 10GB chunk of your database volume is replicated six ways, across three Availability Zones. Aurora continuously backs up your data to Amazon S3, and transparently recovers from physical storage failures; instance failover typically takes less than 30 seconds.

18. How can AWS WAF be integrated with AWS services to enhance web application security?

Answer: AWS WAF (Web Application Firewall) protects web applications from common web exploits. It can be integrated with Amazon CloudFront (the CDN service) and Application Load Balancer, allowing you to create custom rules that block malicious traffic patterns. This means that you can use AWS WAF to protect both your applications accessed via CloudFront distributions and those accessed directly via an Application Load Balancer.

19. What’s the difference between AWS Systems Manager and AWS OpsWorks? How do they help in configuration management?

Answer: AWS Systems Manager provides a unified interface for viewing operational data from multiple AWS services and allows you to automate operational tasks across AWS resources. It aids in patch management, automation, config management, and instance management. On the other hand, AWS OpsWorks is a configuration management service that uses Chef and provides instances of Chef and Puppet. OpsWorks lets you model and set up your Amazon EC2 instances and other AWS resources with Chef cookbooks or Puppet manifests. Both tools assist in automating infrastructure and application management tasks but differ in their approaches and integration points.

20. Explain the purpose and use cases of Amazon Kinesis. How does it compare to traditional messaging systems like SQS or SNS?

Answer: Amazon Kinesis is a platform to stream data on AWS, offering powerful services to make it easier to load and analyze streaming data. Use cases include real-time analytics, dashboards, and telemetry. While SQS (Simple Queue Service) is a distributed message queuing service and SNS (Simple Notification Service) is for pub/sub messaging, Kinesis provides real-time data streaming. SQS and SNS are ideal for decoupling components and sending notifications, while Kinesis focuses on real-time data processing.


# Difference between Security Groups and Network Access Control List (NACL)

![alt text](image-7.png)

Security group is the firewall of EC2 Instances.

Network ACL is the firewall of the VPC Subnets.

## Key Differences: Security group vs NACL

- Scope: Subnet or Instance (where to apply)
Security Groups operate at Instance (Network Interface) level. Security Group has to be assigned explicitly to the instance.

Network ACLs at the subnet level. Applies automatically to all instances deployed in the associated subnet.

- State: Stateful or Stateless
Security groups are stateful. Return traffic is allowed, regardless of the rules.
e.g. If you allow an incoming traffic on port 80, the outgoing traffic on port 80 will be automatically allowed.

Network ACLs are stateless. Return traffic must be explicitly allowed by the rules. Meaning any changes applied to an incoming rule will not be applied to outgoing rule.
e.g. If you allow an incoming port 80, you would also need to apply the rule for outgoing traffic.

- Rule Type: Allow or Deny
Security group supports allow rules only (everything else is denied implicitly). You can specify allow rules, but not deny rules.
e.g. You cannot deny a certain IP address from establishing a connection.

Network ACL supports allow and deny rules.
e.g. By deny rules, you could explicitly deny a certain IP address to establish a connection to an EC2 Instance.

- Rule Process order
Security group evaluates all rules before deciding whether to allow traffic.
(When you associate multiple security groups with a resource, the rules from each security group are aggregated to form a single set of rules that are used to determine whether to allow access.)

Network ACL evaluates rules in order, starting with the lowest numbered rule, when deciding whether to allow traffic.
If matching rule found during evaluation, remaining rules won’t be evaluated.

- Occurrence
Instance can have multiple Security groups.

Subnet can have only one NACL.

- Rule Destination
Security group rule allows CIDR, IP, and Security Group as destinations.

Network ACL rule only allows CIDR as a destination.

- Defense order
Security group first layer of defense, whereas Network ACL is the second layer of defense for outbound/egress traffic.

Network ACL first layer of defense, whereas the Security group is the second layer of defense for inbound/ingress traffic.

# Difference between Internet Gateway and NAT Gateway

![alt text](image-8.png)

Internet Gateway (IGW) allows instances with public IPs to access the internet.
NAT Gateway (NGW) allows instances with no public IPs to access the internet.

## Internet Gateway

- Internet Gateway (IGW) is a horizontally scaled, redundant, and highly available VPC component that allows communication between your VPC and the internet.
- Internet Gateway enables resources (like EC2 instances) in public subnets to connect to the internet. Similarly, resources on the internet can initiate a connection to resources in your subnet using the public.
- If a VPC does not have an Internet Gateway, then the resources in the VPC cannot be accessed from the Internet (unless the traffic flows via a Corporate Network and VPN/Direct Connect).
- Internet Gateway supports IPv4 and IPv6 traffic.
- Internet Gateway does not cause availability risks or bandwidth constraints on your network traffic.
- In order to make subnet public, add a route to your subnet’s route table that directs internet-bound traffic to the internet gateway.
-You can associate exactly one Internet Gateway with a VPC.
-Internet Gateway is not Availability Zone specific.
- There’s no additional charge for having an internet gateway in your account.

## NAT Gateway

- NAT Gateway (NGW) is a managed Network Address Translation (NAT) service.
- NAT Gateway does something similar to Internet Gateway (IGW), but it only works one way: Instances in a private subnet can connect to services outside your VPC but external services cannot initiate a connection with those instances.
- NAT gateways are supported for IPv4 or IPv6 traffic.
- NAT gateway supports the following protocols: TCP, UDP, and ICMP.
- Each NAT gateway is created in a specific Availability Zone and implemented with redundancy in that zone.
- If you have resources in multiple Availability Zones and they share one NAT gateway, and if the NAT gateway’s Availability Zone is down, resources in the other Availability Zones lose internet access.
- To create an Availability Zone-independent architecture, create a NAT gateway in each Availability Zone.
- You can associate exactly one Elastic IP address with a public NAT gateway.
- You are charged for each hour that your NAT gateway is available and each Gigabyte of data that it processes.

# Amazon EKS vs ECS — Comparison

EKS gives an advanced orchestration solution with improved portability between clouds and on-premise systems for enterprise applications.
ECS gives simplicity, availability and seamless deployment to run small applications.



# AWS — Difference between Secrets Manager and Parameter Store (Systems Manager)

AWS gives you two ways to store and manage application configuration data centrally:

- Secrets Manager: It was designed specifically for confidential information (like database credentials, API keys) that needs to be encrypted, so the creation of a secret entry has encryption enabled by default. It also gives additional functionality like rotation of keys.

- Systems Manager Parameter Store: It was designed to cater to a wider use case, not just secrets or passwords, but also application configuration variables like URLs, Custom settings, AMI IDs, License keys, etc.

## Similarities
- Encryption
Both Secrets Manager and Parameter Store can leverage AWS KMS to encrypt values. By using KMS, IAM policies can be configured to control permissions on which IAM users and roles have permission to decrypt the value. Though access to the values can be restricted through IAM, encryption provides an additional layer of security and is sometimes required for compliance.

- Key/Value Store
Both services allow you to store values under a name or key.
Both allow the keys to having prefixes. For example, parameters or secrets can be put in the following prefix schema application/environment/parametername or any other combination of prefixes that meets the need of the application. This is useful since the deployment of the application can reference different parameters/secrets based on the deployment environment.

- CloudFormation Integration
CloudFormation is used as an Infrastructure as a code (IaC) model, and storing secrets in CloudFormation is a bad security practice. You can store the secrets (e.g. Database username and password) in Parameter Store or Secrets Manager which can be referenced in the CloudFormation template so that you just have a pointer to the value in your template instead of containing the secrets in plaintext.

- Versioning
Both services support versioning of secret values. This allows you to view previous versions of your parameters of secret in case you needed them. You can choose to restore the older version of the parameter.
Parameter Store only allows one version of the parameter to be active at any given time.
Secrets Manager allows multiple versions to exist at the same time when you are performing a secret rotation using the staging labels.

## Key Differences
Cost
Secrets Manager: It is paid. The storage cost is $0.40 per secret per month and API interactions cost is $0.05 per 10,000 API calls.

Parameter Store: For Standard parameters, No additional charge for storage and standard throughput. For higher throughput, API interactions cost is $0.05 per 10,000 API calls.
For Advanced parameters, storage cost is $0.05 per advanced parameter per month and API interactions cost is $0.05 per 10,000 API calls.

Secrets Rotation
Secrets Manager: It offers the ability to switch secrets at any given time and can be configured to regularly rotate depending on your requirements. It provides full key rotation integration with few AWS service like RDS, Redshift, DocumentDB. For other services, AWS allows you to write custom key rotation logic using an AWS Lambda function.

Parameter Store: You can write your own function that updates credentials managed by Parameter Store, and invoking it via a CloudWatch scheduled event or Eventbridge.

Cross-account Access
Secrets Manager: Secrets can be accessed from another AWS account. It easier to share the secrets cross-accounts. This is useful if secrets are centrally managed from another AWS account or beneficial for use cases where a customer needs to share a particular secret with a partner.

Parameter Store: Not supported.

Secret Size
Secrets Manager: It can store up to 10KB secret size.

Parameter Store: Standard Parameters can store up to 4096 characters (4KB size) for each entry, and Advanced Parameters can store up to 8KB entries.

Limits
Secrets Manager: It has a limitation of storing 500,000 secrets per region per account.

Parameter Store: It has a limitation of storing 10,000 standard parameters per region per account.

Multiple Regions Replication
Secrets Manager: It lets you easily replicate your secrets in multiple AWS Regions to support applications spread across those Regions as well as disaster recovery scenarios.

Parameter Store: It doesn’t support cross region replication out of the box.

## Use Cases
Choose Secrets Manager if:
You want to store only encrypted values and super easy way to manage the rotation of the secrets. For instance, for organizations that have to be PCI compliant where the mandate is to rotate your passwords every 90d, AWS Secrets Manager makes that a very easy and seamless process.
Choose Parameter Store if:
You want cheaper option to store encrypted or unencrypted secrets.

#  Difference between Application load balancer (ALB) and Network load balancer (NLB)

ALB — Layer 7 (HTTP/HTTPS traffic), Flexible.
NLB — Layer 4 (TLS/TCP/UDP traffic), Static IPs.
CLB — Layer 4/7 (HTTP/TCP/SSL traffic), Legacy, Avoid.

Both Application Load Balancer and Network Load Balancer are designed from the ground up for the modern paradigm of dynamic port configurations as commonly seen in containerized deployments. Picking which load balancer is right for you will depend on the specific needs of your application, such as whether or not network traffic is HTTP, whether you need end-to-end SSL/TLS encryption, and whether or not you want host and path-based traffic routing.

If you are deploying docker containers and using a load balancer to send network traffic to them EC2 Container Service provides tight integration with ALB and NLB so you can keep your load balancers in sync as you start, update, and stop containers across your fleet.

## Application Load Balancer (ALB)

This is the distribution of requests based on multiple variables, from the network layer to the application layer. It is context-aware and can direct requests based on any single variable as easily as it can a combination of variables. Applications are load balanced based on their peculiar behavior and not solely on server (operating system or virtualization layer) information.

This is a feature filled Layer-7 load balancer, HTTP, and HTTPS listeners only. Provides the ability to route HTTP and HTTPS traffic based upon rules, host-based or path based. Like an NLB, each Target can be on different ports. Even supports HTTP/2. Configurable range of health check status codes (CLB only supports 200 OK for HTTP health checks).

Protocols: HTTP, HTTPS

Protocol versions: HTTP/1.1, HTTP/2, gRPC

Target Types: Instance, IP, Lambda

With ALB, it is a requirement that you enable at least two or more Availability Zones.

## Network Load Balancer (NLB)
This is the distribution of traffic based on network variables, such as IP address and destination ports. It is Layer 4 (TCP) and below and is not designed to take into consideration anything at the application layer such as content type, cookie data, custom headers, user location, or the application behavior. It is context-less, caring only about the network-layer information contained within the packets it is directing this way and that.

This is a TCP Load Balancer only that does some NAT magic at the VPC level. It uses EIPs, so it has a static endpoint unlike ALB and CLBs (by default). Each Target can be on different ports.

Protocols: TLS, TCP, UDP, TCP_UDP

Protocol versions: TLS, TCP, UDP, TCP_UDP

Target Types: Instance, IP, ALB

With NLB, Elastic Load Balancing creates a network interface for each Availability Zone that you enable.

## Key Differences: ALB vs NLB

- OSI Layer: Application Load Balancer (as the name implies) works at the Application Layer (Layer 7 of the OSI model, Request level). Network Load Balancer works at the Transport layer (Layer 4 of the OSI model, Connection level).
- Routing: NLB just forward requests whereas ALB examines the contents of the HTTP request header to determine where to route the request. So, an ALB support advanced request (content-based) routing.
- Static IP: ALB doesn’t provide support for static IP addresses whereas NLB provides support for zonal static IP addresses (in each AZ).
- PrivateLink (Endpoint services): NLB provides support for PrivateLink with VPC Endpoints Service integration whereas ALB doesn’t support PrivateLink. Only NLB can be used directly as PrivateLink.
- Elastic Load Balancing now supports forwarding traffic directly from NLB to ALB. With this feature, you can now use AWS PrivateLink and expose static IP addresses for applications built on ALB.
- AWS Load Balancer Controller for Kubernetes: controller provisions ALB when you create a Kubernetes Ingress and NLB when you create a Kubernetes service of type LoadBalancer.
- Application availability: NLB cannot assure the availability of the application. This is because it bases its decisions solely on a network and TCP-layer variables and has no awareness of the application at all. Generally, NLB determines availability based on the ability of a server to respond to ICMP ping or to correctly complete the three-way TCP handshake. ALB goes much deeper and is capable of determining availability based on not only a successful HTTP GET of a particular page but also the verification that the content is as was expected based on the input parameters.
- When considering the deployment of multiple applications on the same host sharing IP addresses (virtual hosts), NLB will not differentiate between Application-A and Application-B when checking availability (indeed it cannot unless ports are different) but ALB will differentiate between two applications by examining the application layer data available to it. This difference means that NLB may end up sending requests to an application that has crashed or is offline, but ALB will never make that same mistake.
- Security: ALB and NLB, both support Security Groups. (Updates on Aug 10, 2023, Network Load Balancer now supports security groups)

## Use Cases

- Choose ALB if:

- Application Load Balancer is best suited for load balancing of HTTP and HTTPS traffic and provides advanced request routing targeted at the delivery of modern application architectures, including microservices and containers.
- Applications need advanced routing (host-based, URL-based, query string based).
- Run multiple services (microservices) behind a single load balancer.

- Choose NLB if:

- Network Load Balancer is best suited for load balancing of TCP traffic where extreme performance is required. It is capable of handling millions of requests per second while maintaining ultra-low latencies, and it is optimized to handle sudden and volatile traffic patterns.
- You want to share/expose your services (e.g. SaaS services) to other consumers in different VPCs using PrivateLink VPC Endpoint.
- You need a static IP address that can be used by applications as the front-end IP of the load balancer.
# When to use: ALB vs. NLB vs. GLB
An ALB is a good choice when you need flexible application-level traffic management and routing. It’s best with microservices, containerized environments, and web applications. Its features—such SSL termination, session persistence, and content-based routing—enable it to offer assistance with complex routing scenarios. 

An NLB is best for high-performance, low-latency, and scalable network-level balancing. Applications that distribute traffic on the transport layer use NLBs, especially considering its reliability. Gaming systems, media streaming services, and major IoT systems use NLBs. 

A GLB is ideal when you’re balancing on the network gateway level. For example, a GLB works well if you manage traffic between cloud and on-premises environments or across different regions. Because it combines OSI layers 3 and 4 balancing, it can route traffic between distinct regions and networks. Because it supports IP-based routing, it can distribute traffic across virtual gateways, so it can offer high scalability and availability.
